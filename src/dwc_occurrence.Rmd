---
title: "Darwin Core mapping for occurrence dataset"
author: Peter Desmet
output:
  md_document:
    variant: markdown_github
    pandoc_args: ["--atx-headers"]
    df_print: kable
knit: (function(input_file, encoding) { rmarkdown::render(input_file, encoding = encoding, output_file = paste0("../reports/",sub(".Rmd", ".md", basename(input_file))))})
---

# `r rmarkdown::metadata$title`

By: `r rmarkdown::metadata$author`

Date: `r Sys.Date()`

```{r configure_knitr, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Setup

Set locale (so we use UTF-8 character encoding):

```{r}
# This works on Mac OS X, might not work on other OS
Sys.setlocale("LC_CTYPE", "en_US.UTF-8")
```

Load libraries:

```{r}
library(tidyverse) # For data transformations

# None core tidyverse packages:
library(magrittr)  # For %<>% pipes
library(stringr)   # For string manipulation

# Other packages
library(janitor)   # For cleaning input data
```

Set file paths (all paths should be relative to this script):

```{r}
raw_data_file = "../data/input/denormalized_observations_50000.csv"
dwc_occurrence_file = "../data/output/dwc_occurrence/occurrence.csv"
deployment_file = "../data/output/temp/deployment.csv"
tag_animal_file = "../data/output/temp/tag_animal.csv"
```

## Read data

Read the source data:

```{r}
raw_data <- read.csv(raw_data_file, fileEncoding = "UTF-8")
```

Clean data somewhat:

```{r}
raw_data %>%
  # Remove empty rows
  remove_empty_rows() %>%
  # Have sensible (lowercase) column names
  clean_names() -> raw_data
```

Save column names as a list (makes it easier to remove them all later):

```{r}
raw_colnames <- colnames(raw_data)
```

List all fields:

```{r}
raw_colnames
```

Number of records:

```{r}
count(raw_data)
```

Preview data:

```{r}
head(raw_data)
```

## Create occurrence core

### Pre-processing

```{r}
occurrence <- raw_data
```

Sort by transmitter and date:

```{r}
occurrence %<>% arrange(detections_transmitter, detections_datetime)
```

### Term mapping

Map the source data to [Darwin Core Occurrence](http://rs.gbif.org/core/dwc_occurrence_2015-07-02.xml) (but in the classic Darwin Core order):

#### type

```{r}
occurrence %<>% mutate(type = "Event")
```

#### language

```{r}
occurrence %<>% mutate(language = "en")
```

#### license

```{r}
occurrence %<>% mutate(license = "http://creativecommons.org/publicdomain/zero/1.0/")
```

#### rightsHolder

Organization who owns the tag (receiver network can be used by all):

```{r}
occurrence %<>% mutate(rightsHolder = recode(as.character(tags_owner_organization),
  "EVINBO"                       = "INBO",
  "INST. VOOR NATUUR-&"          = "INBO",
  "INST. VOOR NATUUR-EN"         = "INBO",
  "INST. VORR NATUUR-&"          = "INBO",
  "LIFEWATCH-INBO"               = "INBO",
  "VLAAMS INSTITUUT VOOR DE ZEE" = "VLIZ",
  .default = "",
  .missing = ""
))

# TODO: was supposed to be animal project organization
```

Show mapped values:

```{r}
occurrence %>% 
  select(tags_owner_organization, rightsHolder) %>%
  group_by_all() %>%
  summarize(records = n()) %>%
  arrange(tags_owner_organization)
```

#### accessRights

```{r}
occurrence %<>% mutate(accessRights = "http://www.inbo.be/en/norms-for-data-use")
```

#### datasetID

```{r}
occurrence %<>% mutate(datasetID = "") # TODO: add DOI
```

#### institutionCode

```{r}
occurrence %<>% mutate(institutionCode = rightsHolder)
```

#### datasetName

```{r}
occurrence %<>% mutate(datasetName = "Acoustic telemetry tracking data of fish in the Scheldt river basin and the Belgian Part of the North Sea (BPNS)")
```

#### basisOfRecord

```{r}
occurrence %<>% mutate(basisOfRecord = "MachineObservation")
```

#### informationWithheld

```{r}
occurrence %<>% mutate(informationWithheld = "see metadata")
```

#### dynamicProperties

```{r}
occurrence %<>% mutate(dynamicProperties = paste0(
  "{\"transmitter\":\"", detections_transmitter, "\", ",
  "\"receiver\":\"", detections_receiver, "\"}"
))
```

#### occurrenceID

```{r}
occurrence %<>% mutate(occurrenceID = paste("otn", "lifewatch", raw_id_pk, sep = ":"))
```

Check for duplicate `occurrenceID`s (should be 0):

```{r}
anyDuplicated(occurrence$occurrenceID)
```

#### sex

```{r}
occurrence %<>% mutate(sex = recode(as.character(animals_sex),
  "F" = "female",
  "M" = "male",
  .default = "",
  .missing = ""
))
```

Show mapped values:

```{r}
occurrence %>%
  select(animals_sex, sex) %>%
  group_by_all() %>%
  summarize(records = n()) %>%
  arrange(animals_sex)
```

#### lifeStage

```{r eval = FALSE}
occurrence %<>% mutate(recode(as.character(raw_life_stage),
  "FV" = "?",
  "FIII" = "?",
  .default = "",
  .missing = ""
))

# TODO: complete this information... or add it to individuals table.
```

#### organismID

```{r}
occurrence %<>% mutate(organismID = animals_animal_id)
# TODO: This one is often NA. detections_transmitter would have been nicer
```

#### eventID

```{r}
# TODO: could potentially be deployment (more a parentEventID).
```

#### eventDate

`datetime` assumed to be UTC. For 3D analyses milliseconds will be required, but these won't be available in the source data until VRL imports are supported.

```{r}
occurrence %<>% mutate(eventDate = format(as.POSIXct(detections_datetime), format = "%Y-%m-%dT%H:%M:%SZ"))
# TODO: verify if UTC
```

#### eventTime

```{r}
# TODO: could be used to indicate local time
```

#### samplingProtocol

```{r}
# TODO: refer to DOI of methodology paper? Can some information be derived from source data?
# receivers_receiver_type: acoustic_telemetry, SVN, active
# receivers_model_number: VR2W, NA, 122325
# animals_capture_method: NA, LINE FISHING, FYKE NETS
```

#### locationID

The `deployments_station_name` is a fixed code for that deployment location. It should always be populated. The `detections_receiver` code is not adequate, as a receiver can be moved from one location to another.

```{r}
occurrence %<>% mutate(locationID = deployments_station_name)
```
```

#### waterBody

```{r}
# TODO: Could be useful to filter? Either based on marine regions gazetteer from coordinates or based on a field in the source data?
```

#### countryCode

```{r}
# TODO: Can be useful to filter and could be derived from coordinates, but trickier for records at sea?
```

#### locality

There is location information available in the `deployments.location_` fields:

```{r}
occurrence %>%
  select(contains("deployments_location")) %>%
  unique() %>%
  head()
```

But these raw Dutch location names are not very useful, so we don't include this information.

#### minimumDepthInMeters

Pressure tags collect depth information, but that won't be available in the source data until VRL imports are supported.

#### decimalLatitude

There are several columns with coordinates information (listing percentage of `NA`s):

```{r}
occurrence %>%
  select(contains("_lat"), contains("_long")) %>% # Looking for _lat(itude) in column name
  select(order(colnames(.))) %>% # Order alphabetically
  sapply(function(x) 100*mean(is.na(x)))
```

Of those the **deployment** coordinates of the receiver are the closest approximation of the position of the fish and always populated (no `NA`s in table above):

```{r}
occurrence %<>% mutate(decimalLatitude = sprintf("%.7f", round(deployments_deploy_lat, digits = 7)))
```

#### decimalLongitude

```{r}
occurrence %<>% mutate(decimalLongitude = sprintf("%.7f", round(deployments_deploy_long, digits = 7)))
```

#### geodeticDatum

```{r}
occurrence %<>% mutate(geodeticDatum = "WGS84")
```

#### coordinateUncertaintyInMeters

```{r}
# Depends on area: sea / Westerscheldt: 200m on average, 500m extreme, while Albertkanaal: 2km
# TODO: on which field should this be based?
# network_project_project?
# animal_project_project?
# detections_receiver?
```

#### georeferenceSources

```{r}
occurrence %<>% mutate(georeferenceSources = "GPS") # TODO: not always GPS, maybe drop term
```

#### georeferenceVerificationStatus

```{r}
occurrence %<>% mutate(georeferenceVerificationStatus = "unverified") # TODO: maybe drop term
```

#### scientificName

```{r}
occurrence %<>% mutate(scientificName = animals_scientific_name)
```

TEST: Show unique values:

```{r}
occurrence %>%
  select(animals_scientific_name) %>%
  group_by_all() %>%
  summarize(records = n())
```

Filter out records with `Sync tag` as scientific name:

```{r}
occurrence %<>% filter(scientificName != "Sync tag")
```

Number of remaining occurrences:

```{r}
nrow(occurrence)
```

#### kingdom

```{r}
occurrence %<>% mutate(kingdom = "animalia")
```

Some other higher classication terms could be populated, but with the limited number of species it's not really useful as extra filters.

#### taxonRank

```{r}
occurrence %<>% mutate(taxonRank = "species") # TODO: all species?
```

#### vernacularName

```{r}
# occurrence %<>% mutate(vernacularName = animals_common_name)
# TODO: ever populated?
```

### Post-processing

Filter out records under a moratorium:

```{r}
occurrence %<>% filter(animal_project_moratorium == 1)
# TODO: or was it network_project_moratorium?
```

Number of remaining occurrences:

```{r}
nrow(occurrence)
```

Remove the original columns:

```{r}
occurrence %<>% select(-one_of(raw_colnames))
```

Preview data:

```{r}
head(occurrence)
```

Save to CSV:

```{r}
write.csv(occurrence, file = dwc_occurrence_file, na = "", row.names = FALSE, fileEncoding = "UTF-8")
```

## Create deployments export

### Pre-processing

Define deployment columns to group by:

```{r}
deployment_column_names <- c(
  "detections_receiver",
#  "detections_station_name",
#  "detections_qc_flag",
#  "detections_file", # Not really relevant for external user
#  "detections_latitude",
#  "detections_longitude",
  "detections_deployment_fk",
#  "detections_signal_to_noise_ratio",
#  "detections_detection_file_id",
  "deployments_station_name",
  "deployments_deploy_date_time",
#  "deployments_recover_date_time", # Not yet in view
#  "deployments_location_name",
#  "deployments_location_manager",
#  "deployments_location_description",
  "deployments_deploy_lat",
  "deployments_deploy_long",
#  "deployments_recover_lat",
#  "deployments_recover_long",
#  "deployments_intended_lat",
#  "deployments_intended_long",
#  "deployments_bottom_depth",
#  "deployments_riser_length",
#  "deployments_instrument_depth",
#  "receivers_serial_number", # Is already part of receiver code
#  "receivers_model_number", # Is already part of receiver code
  "receivers_owner_organization",
  "receivers_status"
)
```

```{r}
raw_data %>%
  select(deployment_column_names) %>%
  group_by_all() %>%
  summarize(detections = n()) %>%
  arrange(raw_receiver) -> deployment
```

### Post-processing

Preview data:

```{r}
head(deployment)
```

Number of records:

```{r}
length(deployment)
```

Remove `raw_` from column names:

```{r}
colnames(deployment) %<>% str_replace_all(., "raw_", "")
```

Save to CSV:

```{r}
write.csv(deployment, file = deployment_file, na = "", row.names = FALSE, fileEncoding = "UTF-8")
```

## Create tag/animal export

### Pre-processing

Define tag/animal columns to group by:

```{r}
tag_animal_column_names <- c(
  "raw_transmitter",
#  "raw_transmitter_name",
#  "raw_transmitter_serial",
#  "raw_sensor_value",
#  "raw_sensor_unit",
#  "raw_sensor2_value",
#  "raw_sensor2_unit",
  "raw_tag_type",
  "raw_tag_model",
  "raw_tag_code_space",
  "raw_tag_owner_pi",
  "raw_tag_owner_organization",
  "raw_tag_min_delay",
  "raw_tag_max_delay",
  "raw_tag_frequency",
  "raw_acoustic_tag_type",
#  "raw_tag_sensor_type",
#  "raw_tag_intercept",
#  "raw_tag_slope",
#  "raw_sensor_value_depth_meters",
  "raw_person_id",
  "raw_animal_id",
  "raw_scientific_name",
#  "raw_common_name",
  "raw_length",
  "raw_length_type",
  "raw_length_units",
  "raw_length2",
  "raw_length2_type",
  "raw_length2_units",
  "raw_weight_units",
#  "raw_age",
#  "raw_age_units",  
  "raw_sex",
  "raw_life_stage",
  "raw_capture_location",
  "raw_capture_depth",
  "raw_utc_release_date_time",
  "raw_comments",
#  "raw_est_tag_life",
  "raw_wild_or_hatchery",
#  "raw_stock",
#  "raw_dna_sample_taken",
  "raw_treatment_type",
#  "raw_dissolved_oxygen",
#  "raw_sedative",
#  "raw_sedative_concentration",
#  "raw_temperature_change",
#  "raw_holding_temperature",
#  "raw_preop_holding_period",
#  "raw_post_op_holding_period",
  "raw_surgery_location",
  "raw_date_of_surgery",
  "raw_anaesthetic",
#  "raw_buffer",
  "raw_anaesthetic_concentration",
#  "raw_buffer_concentration_in_anaesthetic",
#  "raw_anesthetic_concentration_in_recirculation",
#  "raw_buffer_concentration_in_recirculation",
  "raw_catched_date_time",
  "raw_tag_fk",
  "raw_capture_latitude",
  "raw_capture_longitude",
  "raw_release_latitude",
  "raw_release_longitude",
#  "raw_surgery_latitude",
#  "raw_surgery_longitude",
#  "raw_recapture_date",
#  "raw_implant_type",
#  "raw_implant_method",
  "raw_date_modified",
  "raw_date_created",
  "raw_release_location",
  "raw_length3",
  "raw_length3_type",
  "raw_length3_units",
  "raw_length4",
  "raw_length4_type",
  "raw_length4_units",
  "raw_weight",
  "raw_end_date_tag",
  "raw_capture_method",
  "raw_project_fk",
  "raw_animal_project",
  "raw_animal_project_name",
  "raw_animal_project_code",
  "raw_animal_moratorium",
  "raw_network_project",
  "raw_network_project_name",
  "raw_network_project_code",
  "raw_network_moratorium"
)
```

Group by tag/animal information:

```{r}
raw_data %>%
  select(tag_animal_column_names) %>%
  group_by_all() %>%
  summarize(detections = n()) %>%
  arrange(raw_transmitter) -> tag_animal
```

### Post-processing

Preview data:

```{r}
head(tag_animal)
```

Number of records:

```{r}
length(tag_animal)
```

Remove `raw_` from column names:

```{r}
colnames(tag_animal) %<>% str_replace_all(., "raw_", "")
```

Save to CSV:

```{r}
write.csv(tag_animal, file = tag_animal_file, na = "", row.names = FALSE, fileEncoding = "UTF-8")
```
